{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af9bd847",
   "metadata": {},
   "source": [
    "# ðŸŽ¨ Prompt Blending with Stable Diffusion and Gradio\n",
    "This notebook lets you blend two text prompts using classifier-free guidance and visualize the result using Stable Diffusion v1.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2b46fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install diffusers transformers accelerate gradio torch scipy --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd83565a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import gradio as gr\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "use_fp16 = device == \"cuda\"\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\",\n",
    "    torch_dtype=torch.float16 if use_fp16 else torch.float32\n",
    ")\n",
    "pipe = pipe.to(device)\n",
    "pipe.safety_checker = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccc2792",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate_blend(prompt_a, prompt_b, alpha=0.5, guidance_scale=7.5, seed=42):\n",
    "    \"\"\"\n",
    "    Generate a blended image from two prompts using classifier-free guidance.\n",
    "    \"\"\"\n",
    "    generator = torch.Generator(device=device).manual_seed(seed)\n",
    "    max_length = pipe.tokenizer.model_max_length\n",
    "\n",
    "    input_a = pipe.tokenizer(prompt_a, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=max_length).input_ids.to(device)\n",
    "    input_b = pipe.tokenizer(prompt_b, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=max_length).input_ids.to(device)\n",
    "    input_uncond = pipe.tokenizer([\"\"], return_tensors=\"pt\", padding=\"max_length\", max_length=max_length).input_ids.to(device)\n",
    "\n",
    "    embedding_a = pipe.text_encoder(input_a)[0]\n",
    "    embedding_b = pipe.text_encoder(input_b)[0]\n",
    "    uncond_embedding = pipe.text_encoder(input_uncond)[0]\n",
    "    blended_embedding = (1 - alpha) * embedding_a + alpha * embedding_b\n",
    "    text_embeddings = torch.cat([uncond_embedding, blended_embedding], dim=0)\n",
    "\n",
    "    latents = torch.randn(\n",
    "        (1, pipe.unet.in_channels, 64, 64),\n",
    "        generator=generator,\n",
    "        device=device,\n",
    "        dtype=torch.float16 if use_fp16 else torch.float32\n",
    "    ) * pipe.scheduler.init_noise_sigma\n",
    "\n",
    "    pipe.scheduler.set_timesteps(20, device=device)\n",
    "\n",
    "    for t in pipe.scheduler.timesteps:\n",
    "        latent_input = torch.cat([latents] * 2)\n",
    "        latent_input = pipe.scheduler.scale_model_input(latent_input, t)\n",
    "        noise_pred = pipe.unet(latent_input, t, encoder_hidden_states=text_embeddings).sample\n",
    "        noise_uncond, noise_cond = noise_pred.chunk(2)\n",
    "        noise = noise_uncond + guidance_scale * (noise_cond - noise_uncond)\n",
    "        latents = pipe.scheduler.step(noise, t, latents).prev_sample\n",
    "\n",
    "    latents = latents / 0.18215\n",
    "    image = pipe.vae.decode(latents).sample[0]\n",
    "    image = (image / 2 + 0.5).clamp(0, 1)\n",
    "    image = image.cpu().permute(1, 2, 0).numpy()\n",
    "    image = (image * 255).astype(np.uint8)\n",
    "\n",
    "    return Image.fromarray(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69289b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.Interface(\n",
    "    fn=generate_blend,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Prompt A\", value=\"a gothic cathedral at sunrise\"),\n",
    "        gr.Textbox(label=\"Prompt B\", value=\"a futuristic cyberpunk city\"),\n",
    "        gr.Slider(0, 1, value=0.5, step=0.05, label=\"Blend (alpha)\"),\n",
    "        gr.Slider(1, 15, value=7.5, step=0.5, label=\"Guidance Scale\"),\n",
    "        gr.Slider(0, 10000, value=42, step=1, label=\"Seed\"),\n",
    "    ],\n",
    "    outputs=gr.Image(type=\"pil\", label=\"Blended Output\", downloadable=True),\n",
    "    title=\"ðŸŽ¨ Prompt Blend with Stable Diffusion\",\n",
    "    description=\"Blend two prompts using classifier-free guidance in Stable Diffusion. Download the result with a single click.\",\n",
    ").launch(debug=True)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}